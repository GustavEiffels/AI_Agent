research_task:
  description: >
    **Objective:** Conduct a thorough research about {topic}, focusing exclusively on non-financial information.

    **Step 1: Determine Research Sources Based on Company Origin**
    Based on the 'is_korean' input ('{is_korean}'), perform the following:
    - IF '{is_korean}' is 'true' (meaning it's a Korean company):
      - **ONLY** use the 'Naver Search Tool' (or equivalent Korean search tool) to gather information. Prioritize Korean-specific business and industry data.
    - IF '{is_korean}' is 'false' (meaning it's NOT a Korean company):
      - Use **BOTH** the 'Naver Search Tool' (for any relevant Korean mentions or insights) and a general 'International Search Tool' (like Google Search) to gather comprehensive information. Prioritize international business, industry, and market data.

    **Step 2: Information Gathering**
    Make sure you find any interesting and relevant non-financial information given
    the current year is {current_year}. This includes company overview, business activities,
    industry position, major developments, and any recent general non-financial news (e.g., product launches, partnerships, leadership changes, CSR activities, etc.).
    **DO NOT** focus on financial results, stock prices, or market capitalizations.

  expected_output: >
    A list of 5-10 bullet points summarizing the most relevant general and non-financial information about '{topic}'.
    This output should focus on company overview, business activities, recent non-financial news, etc.
  agent: researcher
# config/tasks.yaml

# ðŸ”¹ 1. Financial Data Collection Task (ê¸°ì¡´ financial_taskì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ë¶€ë¶„ ë‹´ë‹¹)
#    - Agent: financial_analyst
#    - Input: {company_name}, {is_korean}
#    - Output:
#        - ì„±ê³µ: {"status": "data_collected", "data": {...}}
#        - í•œêµ­ ê¸°ì—…ì´ë©° OpenDartReader ì‹¤íŒ¨ ì‹œ: {"status": "file_downloaded_needs_parsing", "file_path": "..."}
#        - ì™¸êµ­ ê¸°ì—…ì´ë©° ticker ëª» ì°¾ì€ ê²½ìš°: {"status": "ticker_not_found", "company_name": "..."}
#        - ì™¸êµ­ ê¸°ì—…ì´ë©° YahooFinanceDataTool ì„±ê³µ ì‹œ: {"status": "data_collected", "data": {...}}

financial_data_collection_task:
  description: |
    **Objective:** Collect raw financial data for '{company_name}' based on its origin (Korean or International).

    **Step 1: Determine Company Type & Ticker Acquisition**
    Based on the 'is_korean' input ('{is_korean}'), perform the following:
    - IF '{is_korean}' is 'true' (meaning it's a Korean company):
      - **DO NOT** attempt to find a ticker.
      - Proceed to collecting financial data using the 'Collect Financial Data' tool (CollectFinancialDataTool). This tool will attempt to use OpenDartReader. If OpenDartReader fails, it will download an XML file and return its path.
    - IF '{is_korean}' is 'false' (meaning it's NOT a Korean company):
      - **FIRST**, you **MUST** use the 'Google Search Ticker' tool to find its stock ticker symbol for '{company_name}'.
      - **CRITICAL**: If the 'Google Search Ticker' tool successfully returns a ticker, use this ticker. If it returns 'No clear ticker found for {company_name} in search results.' or any other error/not-found message, explicitly state that the ticker could not be found for '{company_name}'.
      - **THEN**, if a valid ticker was found, proceed to collecting financial data using the 'Collect Financial Data from Yahoo Finance' tool (YahooFinanceDataTool) with the found ticker.
      - If no valid ticker was found, **DO NOT** attempt to collect financial data.
      
    **Step 2: Output Formatting**
    Return a structured JSON object indicating the result of the data collection.
    - If data was collected successfully (either Korean via OpenDartReader or International via YahooFinanceDataTool), return:
      ```json
      {
        "status": "data_collected",
        "data": { ... collected financial data ... }
      }
      ```
    - If it's a Korean company and 'Collect Financial Data' tool downloaded an XML file for parsing, return:
      ```json
      {
        "status": "file_downloaded_needs_parsing",
        "file_path": "path/to/downloaded_xml_file.xml"
      }
      ```
    - If it's an International company and no valid ticker was found, return:
      ```json
      {
        "status": "ticker_not_found",
        "company_name": "{company_name}",
        "reason": "Could not find a valid stock ticker for this international company."
      }
      ```
  expected_output: |
    A JSON object indicating the status of data collection: either successfully collected financial data, 
    a file path requiring parsing, or a notification that a ticker was not found.
  agent: financial_analyst

# ðŸ”¹ 2. Document Parsing Task (ìƒˆë¡œ ì¶”ê°€)
#    - Agent: document_parser
#    - Input: {"status": "file_downloaded_needs_parsing", "file_path": "..."} (financial_data_collection_taskì˜ ê²°ê³¼)
#    - Output: {"status": "parsed_data_ready", "parsed_data": {...}}

document_parsing_task:
  description: |
    **Objective:** Read EVERY provided XML file, identify its financial reporting period, and extract ALL key financial data using your LLM.

    **Step 1: Process Each XML File IN SEQUENCE**
    - You will receive a dictionary containing 'file_paths' (e.g., `{"status": "files_downloaded_needs_parsing", "file_paths": ["path/to/file1.xml", "path/to/file2.xml", ...]}`).
    - **You MUST process EACH AND EVERY 'file_path' in the provided list.** For each 'file_path':
      - **Use the 'Read and Delete XML File' tool to read the XML content as a string.** This tool will automatically delete each file after reading.

    **Step 2: Parse XML Content with LLM for Each File**
    - After receiving the XML content string from the tool for a given file, **you MUST use your LLM reasoning capabilities to perform the following**:
      - **Identify the precise financial reporting period** for that specific report (e.g., "2023_Annual" for a 2023 annual report, or "2023_1Q" for a Q1 report). This period will serve as a unique key for the data from this report.
      - **Extract the most recent values for the following specific financial items into a JSON object**:
        - `asset_moveable` (ìœ ë™ìžì‚° / Current Assets)
        - `asset_unmoveable` (ë¹„ìœ ë™ìžì‚° / Non-Current Assets)
        - `bet_moveable` (ìœ ë™ë¶€ì±„ / Current Liabilities)
        - `bet_unmoveable` (ë¹„ìœ ë™ë¶€ì±„ / Non-Current Liabilities)
        - `amount_bet` (ë¶€ì±„ì´ê³„ / Total Liabilities)
        - `amount_asset` (ìžë³¸ì´ê³„ / Total Capital/Equity)
        - `revenue` (ë§¤ì¶œì•¡ / Revenue)
        - `gross_profit` (ë§¤ì¶œì´ì´ìµ / Gross Profit)
        - `operating_income` (ì˜ì—…ì´ìµ / Operating Income)
        - `net_income` (ë‹¹ê¸°ìˆœì´ìµ / Net Income)
      
      - Ensure values contain only numbers, remove commas (,), and currency symbols ('ì›'). Assume the unit is 'KRW' (Korean Won).
      - If a specific item is not found or cannot be reliably extracted, mark its value as `null`.

    **Step 3: AGGREGATE ALL Parsed Data into a Single Output**
    - **Crucially, you MUST collect and aggregate the parsed JSON data from ALL files you process.**
    - **Create a single, comprehensive final JSON object.** The top-level keys of this final object should be the identified financial periods (e.g., "2023_Annual", "2022_4Q"), and their values should be the extracted financial data dictionaries for that period.
    - If multiple files provide data for the **same exact period**, explicitly state the rule you applied (e.g., "used data from the latest filed report for YYYY_Annual") within your thought process, and ensure the most appropriate data is kept.
    - **Your final output for this task MUST contain data for ALL parsed periods.**

    Return this final aggregated JSON object.
    If parsing critically fails for all files, return:
    ```json
    {
      "status": "parsing_failed",
      "reason": "Could not parse financial data from any of the provided XML files.",
      "original_file_paths": ["...", "..."]
    }
    ```
  expected_output: |
    A JSON object containing financial data, where keys are financial periods (e.g., "2023_Annual", "2022_4Q"),
    and values are dictionaries of extracted financial items. **This output MUST include data for ALL periods found in the input files.**
    Example:
    {
      "2023_Annual": {
        "asset_moveable": ...,
        "revenue": ...,
        ...
      },
      "2022_Annual": {
        "asset_moveable": ...,
        "revenue": ...,
        ...
      },
      "status": "parsed_data_ready"
    }
    Or an error message if parsing failed across all files.
  agent: document_parser
financial_analysis_task:
  description: |
    **Objective:** Conduct a comprehensive financial analysis for '{company_name}' based on the provided financial data.

    **Step 1: Data Consolidation**
    - You will receive financial data from either the 'financial_data_collection_task' (if OpenDART/Yahoo succeeded) or the 'document_parsing_task' (if XML parsing was necessary and successful).
    - **CRITICAL**: First, check the input data's 'status'.
      - IF the status is 'ticker_not_found' (from 'financial_data_collection_task'), **STOP** the analysis and proceed directly to Step 4.
      - IF the status is 'parsing_failed' (from 'document_parsing_task'), **STOP** the analysis and proceed directly to Step 4.
      - OTHERWISE, consolidate the provided financial data for analysis.
        - If data is from 'financial_data_collection_task', it will be in the format: `{"status": "data_collected", "data": {"YYYY_Q": {...}}}`. Use the 'data' part.
        - If data is from 'document_parsing_task', it will be in the format: `{"status": "parsed_data_ready", "parsed_data_by_file": {"YYYY_Annual_or_Q": {...}, ...}}`. Use the 'parsed_data_by_file' part.
        - **Combine ALL available data from ALL provided periods into a coherent time-series for analysis.** Ensure consistency in financial item keys (e.g., `revenue`, `operating_income`, `asset_moveable`, etc.) across all periods. Sort the data by period (e.g., chronologically) for trend analysis. Prioritize the most recent and complete dataset for each period if duplicates exist.

    **Step 2: Comprehensive Time-Series Analysis**
    - Perform a comprehensive time-series analysis of key financial metrics (using the following exact keys for consistency):
      - `revenue`, `gross_profit`, `operating_income`, `net_income`
      - `asset_moveable`, `asset_unmoveable`, `amount_asset`
      - `bet_moveable`, `bet_unmoveable`, `amount_bet`
    - Analyze trends, significant changes, and inter-relationships between these metrics over the available period (ideally approximately the last two years, all available quarters/years).

    **Step 3: Derive Financial Outlook & Risks/Opportunities**
    - Based on your analysis, derive a **forward-looking financial outlook (ì „ë§)** for the company, identifying potential future performance and risks.

    **Step 4: Final Output Generation**
    The final output should be a structured JSON object.

    If analysis was performed (data was successfully collected/parsed), the JSON should include:
    ```json
    {
      "company_name": "{company_name}",
      "key_trends": {
        "revenue_trend": "...",
        "operating_income_trend": "...",
        "net_income_trend": "...",
        "asset_liability_structure_trend": "...",
        "profitability_trend": "...",
        "liquidity_trend": "..."
      },
      "financial_outlook": "...",
      "risks_and_opportunities": {
        "risks": "...",
        "opportunities": "..."
      },
      "data": { # This is the main change: consolidating raw data under a single 'data' key
        "YYYY_Annual_or_Q": { # Example: "2023_Annual", "2022_4Q"
          "asset_moveable": ...,
          "asset_unmoveable": ...,
          "bet_moveable": ...,
          "bet_unmoveable": ...,
          "amount_bet": ...,
          "amount_asset": ...,
          "revenue": ...,
          "gross_profit": ...,
          "operating_income": ...,
          "net_income": ...
        }
      },
      "status": "data_collected"
    }
    ```
    If financial analysis was NOT applicable (international company with no valid ticker, or parsing failed), the JSON should be:
    ```json
    {
      "company_name": "{company_name}",
      "status": "Financial analysis not applicable",
      "reason": "Could not find a valid stock ticker for this international company OR parsing of the auditor report failed."
    }
    ```
  expected_output: |
    A structured JSON object representing the comprehensive financial analysis,
    or an object indicating non-applicability due to missing ticker or parsing failure.
  agent: financial_analyst

news_collection_task:
  description: >
    **Objective:** Collect the latest 5-10 relevant news articles about '{topic}'.

    **Step 1: Determine News Sources Based on Company Origin**
    Based on the 'is_korean' input ('{is_korean}'), perform the following:
    - IF '{is_korean}' is 'true' (meaning it's a Korean company):
      - **ONLY** use the 'Naver News Tool' to collect news.
    - IF '{is_korean}' is 'false' (meaning it's NOT a Korean company):
      - Use **BOTH** the 'Naver News Tool' and the 'Yahoo News Tool' to collect news, prioritizing relevant international sources from Yahoo.

    **Step 2: News Collection and Summarization**
    - Collect approximately 5-10 recent and relevant news articles.
    - For each article, extract its publication date, source name, headline, a brief (2-3 sentence) summary, and the URL.
    - Ensure the summaries are concise and capture the main points of the article.
  expected_output: >
    A list of dictionaries, where each dictionary represents a news article
    and contains 'date', 'source', 'headline', 'summary', and 'url' fields.
    For example:
    ```json
    [
      {
        "date": "2024-07-15",
        "source": "ë„¤ì´ë²„ ë‰´ìŠ¤",
        "headline": "ABC ê¸°ì—…, ì‹ ê¸°ìˆ  ê°œë°œë¡œ ì‹œìž¥ ì„ ë„",
        "summary": "ABC ê¸°ì—…ì´ ìµœê·¼ í˜ì‹ ì ì¸ ì‹ ê¸°ìˆ ì„ ë°œí‘œí•˜ë©° ê´€ë ¨ ì‹œìž¥ì—ì„œ ë…ë³´ì ì¸ ìœ„ì¹˜ë¥¼ í™•ë³´í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ì´ëŠ” ìƒì‚°ì„± í–¥ìƒê³¼ ë¹„ìš© ì ˆê°ì— í¬ê²Œ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ì£¼ìš” ê²½ìŸì‚¬ë“¤ë„ ABC ê¸°ì—…ì˜ ì›€ì§ìž„ì„ ì£¼ì‹œí•˜ê³  ìžˆìŠµë‹ˆë‹¤.",
        "url": "[http://news.naver.com/article/123](http://news.naver.com/article/123)"
      },
      {
        "date": "2024-07-14",
        "source": "Yahoo Finance",
        "headline": "XYZ Corp. Reports Strong Q2 Earnings",
        "summary": "XYZ Corporation announced better-than-expected earnings for the second quarter, driven by robust sales in its international markets. The company's stock price saw a significant surge following the announcement. Analysts are optimistic about its future growth trajectory.",
        "url": "[http://finance.yahoo.com/news/article/456](http://finance.yahoo.com/news/article/456)"
      }
    ]
    ```
  agent: news_collector

reporting_task:
  description: >
    Review all the context provided from previous tasks to synthesize a comprehensive report about '{topic}'.
    Specifically, you will receive three main pieces of context: # <--- ì—¬ê¸°ì„œ 2ê°œì—ì„œ 3ê°œë¡œ ë³€ê²½
    1.  **General Research Context:** The output from 'research_task' (a list of bullet points summarizing general company information).
    2.  **Financial Analysis Context:** The output from 'financial_task' (a structured JSON object containing detailed financial data and analysis).
    3.  **News Articles Context:** The output from 'news_collection_task' (a list of summarized news articles in the format: {"date": ..., "source": ..., "headline": ..., "summary": ..., "url": ...}). # <--- ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€

    Your primary goal is to integrate all this information into a single, cohesive, comprehensive report,
    strictly adhering to the `ComprehensiveReportOutput` Pydantic schema for the final JSON output.

    **CRITICAL: All content within the JSON fields (e.g., company_overview, trends, outlook) MUST be written in Korean.**

    Fill in all the following fields within the final JSON object. Ensure each field is populated with meaningful Korean content,
    drawing insights from BOTH the General Research Context, the Financial Analysis Context, AND the News Articles Context. # <--- ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ í™œìš© ëª…ì‹œ
    DO NOT leave any field empty or null if information is available or can be reasonably inferred.

    - **company_overview**: ê¸°ì—…ì˜ ì‚¬ì—…, ì‚°ì—…, ì£¼ìš” í™œë™ì— ëŒ€í•œ ê°„ê²°í•œ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤. (General Research Contextì—ì„œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ)
    - **latest_trends_and_strategy**: ê°€ìž¥ ìµœê·¼ì˜ ì¤‘ìš”í•œ ê°œë°œ ì‚¬í•­, ì‹œìž¥ ë™í–¥ ë° ì „ëžµì  ì´ë‹ˆì…”í‹°ë¸Œë¥¼ ìžì„¸ížˆ ì„¤ëª…í•©ë‹ˆë‹¤. (General Research Context, Financial Analysis Context, ê·¸ë¦¬ê³  News Articles Context ëª¨ë‘ í™œìš©)
    - **business_direction**: ë™í–¥ ë° ì „ëžµì„ ë°”íƒ•ìœ¼ë¡œ, íšŒì‚¬ì˜ ë¯¸ëž˜ ì „ëžµì  ì´ˆì , ì£¼ìš” ì„±ìž¥ ì˜ì—­ ë° ìž¥ê¸° ë¹„ì „ì„ ëª…í™•ížˆ ì„¤ëª…í•©ë‹ˆë‹¤. (General Research Context, Financial Analysis Context, ê·¸ë¦¬ê³  News Articles Context ëª¨ë‘ í™œìš©)

    - **detailed_financial_analysis**: **Financial Analysis Contextì—ì„œ ì œê³µëœ JSON ê°ì²´ ë‚´ìš©ì„ ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤.** ì´ëŠ” 'financial_task'ì˜ ëª¨ë“  ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ê³  ìžˆì–´ì•¼ í•©ë‹ˆë‹¤.

    - **financial_performance_and_analysis**: íšŒì‚¬ì˜ ìž¬ë¬´ ê±´ì „ì„±, ì§€ë‚œ ì•½ 2ë…„ê°„ì˜ ì„±ê³¼ ë° ì œê³µëœ ë°ì´í„°ì—ì„œ ë„ì¶œëœ ì£¼ìš” ìž¬ë¬´ í•˜ì´ë¼ì´íŠ¸ì— ëŒ€í•œ ì „ë°˜ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. (ì£¼ë¡œ 'detailed_financial_analysis'ì˜ ìš”ì•½ ë¶€ë¶„ í™œìš©)
    - **revenue_and_profitability_trends**: ì´ ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµì˜ ì¶”ì„¸ë¥¼ ë¶„ì„í•˜ê³ , ì„±ìž¥ë¥ , ë§ˆì§„, ìˆ˜ìµì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ì„ ìƒì„¸í•œ ìž¬ë¬´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…¼í•©ë‹ˆë‹¤. ('detailed_financial_analysis'ì˜ 'financial_data_by_quarter' ë° 'key_trends' í™œìš©)
    - **asset_and_liability_structure**: ìœ ë™/ë¹„ìœ ë™ ìžì‚° ë° ë¶€ì±„ì˜ êµ¬ì„±ê³¼ ì¶”ì„¸ë¥¼ ìƒì„¸ížˆ ì„¤ëª…í•˜ê³ , ìœ ë™ì„±, ì§€ê¸‰ ëŠ¥ë ¥ ë° ë¶€ì±„ ê´€ë¦¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ('detailed_financial_analysis'ì˜ 'financial_data_by_quarter' ë° 'key_trends' í™œìš©)
    - **financial_outlook_and_cash_flow**: ë¯¸ëž˜ ìž¬ë¬´ ì „ë§(ì „ë§)ì„ ì œì‹œí•˜ê³ , íšŒì‚¬ì˜ í˜„ê¸ˆ íë¦„ ì°½ì¶œ ë° í™œìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤. ('detailed_financial_analysis'ì˜ 'financial_outlook' í™œìš©)
    - **risks_and_opportunities**: ì´ í•„ë“œëŠ” ë‘ ê°œì˜ ì¤‘ì²©ëœ JSON ê°ì²´('risks', 'opportunities')ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ('detailed_financial_analysis'ì˜ 'risks_and_opportunities' ë¦¬ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì„¤ëª… í˜•íƒœë¡œ ì „í™˜)
      - **risks**: ì£¼ìš” ìž ìž¬ì  ìœ„í—˜ ìš”ì¸ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.
      - **opportunities**: ì£¼ìš” ìž ìž¬ì  ê¸°íšŒ ìš”ì¸ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.
    - **social_responsibility_and_contribution**: ê¸°ì—…ì˜ ì‚¬íšŒì  ì±…ìž„(CSR) ë° ì‚¬íšŒ ê³µí—Œ í™œë™ì— ëŒ€í•œ ë…¸ë ¥ê³¼ ì´ë‹ˆì…”í‹°ë¸Œë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. (General Research Contextì—ì„œ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ)
    - **recent_news**: **ë‰´ìŠ¤ ê¸°ì‚¬ ì»¨í…ìŠ¤íŠ¸(News Articles Context)ì—ì„œ ìˆ˜ì§‘ëœ ê° ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ì—¬ ëª©ë¡ í˜•íƒœë¡œ ì œê³µí•©ë‹ˆë‹¤.** ê° ê¸°ì‚¬ì˜ 'headline', 'source', 'date', 'url'ì„ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê²Œ ìž‘ì„±í•˜ë˜, í•µì‹¬ ìš”ì•½ì„ ë°˜ë“œì‹œ í¬í•¨í•©ë‹ˆë‹¤. # <--- ìƒˆë¡œ ì¶”ê°€ëœ í•„ë“œì™€ ì‚¬ìš© ì§€ì¹¨
    - **conclusion**: ì „ì²´ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ê³ , íšŒì‚¬ì˜ ë¯¸ëž˜ ì „ë§ì— ëŒ€í•œ ìµœì¢… í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. (ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ë¥¼ í†µí•©í•˜ì—¬ ê²°ë¡  ë„ì¶œ)

    **IMPORTANT:** If the 'financial_task' output indicates that financial analysis was NOT applicable (i.e., it contains `{"status": "Financial analysis not applicable", ...}`), then you **MUST** populate only the 'company_name', 'status', and 'reason' fields in the output JSON. In this specific case, all other fields (including `detailed_financial_analysis` and `recent_news`) should be set to `null` or an empty string as per the Pydantic schema's allowance for optional/default values, reflecting that financial analysis could not be completed.

    **Output ONLY the JSON object. Do not include any conversational text, markdown fences (```json), or other extraneous information.**

  expected_output: |
      A structured JSON object representing the comprehensive report, strictly adhering to the `ComprehensiveReportOutput` Pydantic model.
      This report synthesizes all available information, including detailed financial analysis and recent news from preceding tasks. All content within the JSON fields MUST be in Korean.
  agent: reporting_analyst